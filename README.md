		1. 21 октября в 22:52 UTC проводились плановые ремонтные работы по замене неисправного оптического оборудования 100G
		
		2. Ремонтные работы привели к потере связи между сетевым узлом на Восточном побережье (US East Coast) и основным дата-центром на Восточном побережье. Подключение между ними восстановилось через 43 секунды, но это короткое отключение вызвало цепочку событий, которые привели к 24 часам и 11 минутам деградации сервиса.
		
		3. На нескольких сервисах GitHub.com пострадали несколько сетевых разделов и последующим сбоем базы данных, что привело к отображению устаревшей и непоследовательной информации. На протяжении почти всего сбоя GitHub также не мог обрабатывать webhooks, создавать и публиковать сайты GitHub Pages.

		4. Внутренние системы мониторинга начали генерировать оповещения, указывающие на многочисленные сбои в работе систем. Далее подключилась группа реагирования.

		5. Группа реагирования подключила к работе координатора инцидетов, а также привлекли к работе дополнительных разработчиков из инженерной группы БД.
		
		6. - Остановили выполнение заданий, которые пишут метаданные типа пуш-запросов.
		   - Восстановили файлы из бэкапа, 
		   - Синхронизировали реплики на обоих сайтах
		   - Вернуться к стабильной топологии обслуживания
		   - Возобновили обработку заданий в очереди.

		 7. 22:54 Начали приходить оповещения о сбоях
		    23:02 Инженеры первой группы реагирования определили, что топологии для многочисленных кластеров БД находятся в неожиданном состоянии.
		    23:07 Группы реагирования подключила к работе координатора инцидентов.
		    23:13 К работе подключились дополнительные разработчики из инженерной группы БД.
		    23:19 Остановили выполнение заданий, которые пишут метаданные типа пуш-запросов.
		    00:05 Начали разрабатывать план устранения несогласованности данных и запустили процедуры отработки отказа для MySQL.
		    00:41 Инициирован процесс резервного копирования для всех затронутых кластеров MySQL, и инженеры отслеживали прогресс.
		    06:51 Несколько кластеров в восточном ЦОД завершили восстановление из резервных копий и начали реплицировать новые данные с Западным побережьем.
		    11:12 Все первичные БД вновь переведены на Восток.
		    16:24 Устранили проблемы задержки и доступности.
		    16:45 Сбалансировали возросшую нагрузку, связанную с отставанием
		    23:03 Все незавершённые события вебхуков и сборки Pages обработаны, а целостность и правильная работа всех систем подтверждена.

		 8. - Устранение несоответствующих данных путем репликации записей в БД
		    - Коммуникация с пользователями сервиса
		    - Отрегулировали конфигурацию Orchestrator, чтобы запретить перемещение первичных БД за границы региона.
		    - Ускорили миграцию на новую систему отчётности по статусам.
		    - Запустили общекорпоративную инженерную инициативу для поддержки обслуживания трафика GitHub
		    - Начали системную практику проверки сценариев сбоев.


